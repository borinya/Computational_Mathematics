{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import cv2 as cv2\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Type, Dict, Any\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, datasets\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os.path\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables import Keypoint, KeypointsOnImage\n",
    "import os\n",
    "from threading import Thread\n",
    "from queue import Empty, Queue\n",
    "import threading\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "import accimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.10 |Anaconda, Inc.| (default, May  8 2020, 02:54:21) \\n[GCC 7.3.0]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bf1871029b2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m378\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# обнулили генератор рандома у торча\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m378\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# обнулили генератор рандома у нампая\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeterministic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;31m# ждем одинаковый результат у GPU и CPU Для одинаковых данны переданных торчу\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;31m# вроде аналогично строчке выше\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(378) # обнулили генератор рандома у торча\n",
    "np.random.seed(378)# обнулили генератор рандома у нампая\n",
    "torch.backends.cudnn.deterministic = True # ждем одинаковый результат у GPU и CPU Для одинаковых данны переданных торчу\n",
    "torch.backends.cudnn.benchmark = False # вроде аналогично строчке выше\n",
    "ia.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.device_count()\n",
    "device1 = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" )\n",
    "print(device1)\n",
    "device2 = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_train(model): # запускаем обучение всех слоев\n",
    "    for param in model.parameters(): \n",
    "        param.requires_grad = True\n",
    "def draw_circle(image, landmarks): # дорисовываем окружность на изображении и возвращаем обратно\n",
    "    imageWithCircle = cv2.circle(image, (int(landmarks[0][0]),int(landmarks[0][1]) ),int(landmarks[0][2]), (255, 0 , 0),  10)\n",
    "    return imageWithCircle\n",
    "\n",
    "\n",
    "def show_landmarks(image, landmarks): # конкретно эта функция, скорее всего не понадобится\n",
    "    \"\"\"Show image with landmarks\"\"\"\n",
    "    plt.imshow(draw_circle(image,landmarks) )\n",
    "    plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker='.', c='r') # начало координат не совпадает , надо учесть\n",
    "    # для картинки надо, для нейросетки не нужно, начало координат должно совпасть\n",
    "    # в numpy 0-левая координата - у, первая - иксы(столбцы)\n",
    "    # порисовать диск солнце порисовать кружочки через opencv(там с координатами тоже не все гладко, надо внимательно смотреть)\n",
    "    # размеры реальных снимков 1920х1920 а не 1200х1200, надо как-то или к долям 1 или сразу в 1920х1920 формат\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    \n",
    "def calculate_loss(model_result : torch.tensor, \n",
    "                   data_target  : torch.tensor,\n",
    "                   loss_function: torch.nn.Module = torch.nn.MSELoss()): #reduction = None\n",
    "    lossXY =  (loss_function(model_result[:,:2], data_target[:,:2]))**(0.5) # тут из батчей получаю, править\n",
    "    lossR =  loss_function(model_result[:,2], data_target[:,2]) # потом корень извлечь\n",
    "    return { lossXY.item(), lossR.item() }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddCoords(nn.Module):\n",
    "\n",
    "    def __init__(self, with_r=False):\n",
    "        super().__init__()\n",
    "        self.with_r = with_r\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_tensor: shape(batch, channel, x_dim, y_dim)\n",
    "        \"\"\"\n",
    "        batch_size, _, x_dim, y_dim = input_tensor.size()\n",
    "\n",
    "        xx_channel = torch.arange(x_dim).repeat(1, y_dim, 1)\n",
    "        yy_channel = torch.arange(y_dim).repeat(1, x_dim, 1).transpose(1, 2)\n",
    "\n",
    "        xx_channel = xx_channel.float() / (x_dim - 1)\n",
    "        yy_channel = yy_channel.float() / (y_dim - 1)\n",
    "\n",
    "        xx_channel = xx_channel * 2 - 1\n",
    "        yy_channel = yy_channel * 2 - 1\n",
    "\n",
    "        xx_channel = xx_channel.repeat(batch_size, 1, 1, 1).transpose(2, 3)\n",
    "        yy_channel = yy_channel.repeat(batch_size, 1, 1, 1).transpose(2, 3)\n",
    "\n",
    "        ret = torch.cat([\n",
    "            input_tensor,\n",
    "            xx_channel.type_as(input_tensor),\n",
    "            yy_channel.type_as(input_tensor)], dim=1)\n",
    "\n",
    "        if self.with_r:\n",
    "            rr = torch.sqrt(torch.pow(xx_channel.type_as(input_tensor) - 0.5, 2) + torch.pow(yy_channel.type_as(input_tensor) - 0.5, 2))\n",
    "            ret = torch.cat([ret, rr], dim=1)\n",
    "\n",
    "        return ret\n",
    "\n",
    "\n",
    "class CoordConv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, with_r=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.addcoords = AddCoords(with_r=with_r)\n",
    "        in_size = in_channels+2\n",
    "        if with_r:\n",
    "            in_size += 1\n",
    "        self.conv = nn.Conv2d(in_size, out_channels, **kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ret = self.addcoords(x)\n",
    "        ret = self.conv(ret)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes: int = 1000) -> None:\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            CoordConv(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            CoordConv(64, 192, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(num_features=192),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            CoordConv(192, 384, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=384),\n",
    "            nn.ReLU(inplace=True),\n",
    "            CoordConv(384, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            CoordConv(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.BatchNorm1d(num_features=4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.BatchNorm1d(num_features=4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "#             nn.Linear(4096,num_classes),\n",
    "            nn.Linear(in_features=4096, out_features=256, bias=True),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=128, bias=True),\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.ReLU(), # SeLU или GeLU возможно подойдут лучше, надо поиграться\n",
    "#             nn.Linear(in_features=128, out_features=3, bias=True)\n",
    "            \n",
    "            ###### Coords only - without radius ######\n",
    "            nn.Linear(in_features=128, out_features=2, bias=True)\n",
    "            ###### Coords only - without radius ######\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = AlexNet()\n",
    "\n",
    "for param in alexnet.parameters(): # разрешаем обучаться alexnet\n",
    "    param.requires_grad = True\n",
    "\n",
    "alexnet = alexnet.to(device1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# упомянуть челиков из imgaug\n",
    "## тут агментация данных дальше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),# horizontally flip 20% of the images flipud\n",
    "    iaa.Flipud(0.5),# vertically flip 20% of the images flipud добавить на 180 градусов поворот\n",
    "    iaa.GaussianBlur(sigma=(0, 5)), # blur images with a sigma of 0 to 0.5\n",
    "    #iaa.Invert(0.1) # пока уберем\n",
    "    iaa.Affine(rotate=(-180,180))# поворот на 180 через афииные преобразования\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(dataset_dir):\n",
    "    image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir)]\n",
    "    return image_filenames\n",
    "\n",
    "\n",
    "class thread_killer(object):    \n",
    "    \"\"\"Boolean object for signaling a worker thread to terminate\"\"\"\n",
    "    def __init__(self):\n",
    "        self.to_kill = False\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.to_kill\n",
    "\n",
    "    def set_tokill(self, tokill):\n",
    "        self.to_kill = tokill\n",
    "\n",
    "\n",
    "def threaded_batches_feeder(tokill, batches_queue, dataset_generator):\n",
    "    while tokill() == False:\n",
    "        for img, landmarks in dataset_generator:\n",
    "            batches_queue.put((img, landmarks), block=True)\n",
    "            if tokill() == True:\n",
    "                return\n",
    "\n",
    "\n",
    "def threaded_cuda_batches(tokill,cuda_batches_queue,batches_queue):\n",
    "    while tokill() == False:\n",
    "        (img, landmarks) = batches_queue.get(block=True)\n",
    "        img = torch.from_numpy(img)\n",
    "        landmarks = torch.from_numpy(landmarks)       \n",
    "        \n",
    "        img = Variable(img.float()).to(device1)\n",
    "        \n",
    "#         landmarks = Variable(landmarks.float()).view(-1,3).to(device1)\n",
    "        ###### Coords only - without radius ######\n",
    "        landmarks = Variable(landmarks.float()).view(-1,2).to(device1)\n",
    "        ###### Coords only - without radius ######\n",
    "        \n",
    "        cuda_batches_queue.put((img, landmarks), block=True)\n",
    "        \n",
    "        if tokill() == True:\n",
    "            return\n",
    "\n",
    "\n",
    "class threadsafe_iter:\n",
    "    \"\"\"\n",
    "    Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            return next(self.it)\n",
    "\n",
    "def get_objects_i(objects_count):\n",
    "    \"\"\"Cyclic generator of paths indices\n",
    "    \"\"\"\n",
    "    current_objects_id = 0\n",
    "    while True:\n",
    "        yield current_objects_id\n",
    "        current_objects_id  = (current_objects_id + 1) % objects_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SunLandmarksDataset(Dataset):\n",
    "    \"\"\"Sun Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, batch_size, transform = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(csv_file,delimiter=',')\n",
    "        self.root_dir = root_dir\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.objects_id_generator = threadsafe_iter(get_objects_i(self.landmarks_frame.shape[0]))\n",
    "        \n",
    "        self.lock = threading.Lock()  # mutex for input path\n",
    "        self.yield_lock = threading.Lock()  # mutex for generator yielding of batch\n",
    "        self.init_count = 0\n",
    "        self.cache = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def shuffle(self):\n",
    "        self.landmarks_frame = shuffle(self.landmarks_frame)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            with self.lock:\n",
    "                if (self.init_count == 0):\n",
    "                    self.shuffle()\n",
    "                    self.imgs = []\n",
    "                    self.landmarks = []\n",
    "                    self.init_count = 1\n",
    "            \n",
    "            for obj_id in self.objects_id_generator:\n",
    "                img_name = os.path.join(self.root_dir , self.landmarks_frame.iloc[obj_id, 0])\n",
    "                if img_name in self.cache:\n",
    "                    img = self.cache[img_name]\n",
    "                else:\n",
    "                    img = accimage.Image(img_name)\n",
    "                    image_np = np.empty([img.channels, img.height, img.width], dtype=np.uint8)\n",
    "                    img.copyto(image_np)\n",
    "                    self.cache[img_name] = img\n",
    "                    \n",
    "                img = np.transpose(image_np, (1, 2, 0))\n",
    "                \n",
    "                landmarks = self.landmarks_frame.iloc[obj_id, 1:]\n",
    "                landmarks = np.array([landmarks])\n",
    "                landmarks = landmarks.astype('float').reshape(1, 3)\n",
    "                \n",
    "                kps = KeypointsOnImage([\n",
    "                        Keypoint(x=landmarks[0,0]*1920, y=landmarks[0,1]*1920) # домножил, тк нормировал\n",
    "                ], shape=img.shape)\n",
    "                image_aug, landmarks_after =seq(image = img, keypoints = kps) # тут применяю аугментацию к фотке и целевой переменной\n",
    "                landmarks[0,0] = landmarks_after.keypoints[0].x/1920 # обратно отнормировал \n",
    "                landmarks[0,1] = landmarks_after.keypoints[0].y/1920\n",
    "                img = image_aug\n",
    "                \n",
    "                img = img.transpose((2, 0, 1))[np.newaxis,...] # для тензоров\n",
    "                landmarks = landmarks[np.newaxis,...]\n",
    "                \n",
    "                ###### Coords only - without radius ######\n",
    "                landmarks = landmarks[:,:,:2]\n",
    "                ###### Coords only - without radius ######\n",
    "                \n",
    "                # Concurrent access by multiple threads to the lists below\n",
    "                with self.yield_lock:\n",
    "                    if (len(self.imgs)) < self.batch_size:\n",
    "                        self.imgs.append(img)\n",
    "                        self.landmarks.append(landmarks)\n",
    "                    if len(self.imgs) % self.batch_size == 0:\n",
    "                        self.imgs = np.concatenate(self.imgs, axis=0)\n",
    "                        self.landmarks = np.concatenate(self.landmarks, axis=0)\n",
    "                        yield (self.imgs, self.landmarks)\n",
    "                        self.imgs, self.landmarks = [], []\n",
    "                        \n",
    "            # At the end of an epoch we re-init data-structures\n",
    "            with self.lock:\n",
    "                self.landmarks_frame = shuffle(self.landmarks_frame)\n",
    "                self.init_count = 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = image.copy() # \n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'landmarks': torch.from_numpy(landmarks)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "sun_dataset_train = SunLandmarksDataset(csv_file='sun_disk_pos_database01train.csv',\n",
    "                                        root_dir='/app/images',\n",
    "                                        transform=None,\n",
    "                                        batch_size=batch_size)\n",
    "sun_dataset_test = SunLandmarksDataset(csv_file='sun_disk_pos_database01test.csv',\n",
    "                                       root_dir='/app/images',\n",
    "                                       transform=None,\n",
    "                                       batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for img_batch, lm_batch in sun_dataset_train:\n",
    "    break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "img_batch.shape, lm_batch.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "img = torch.from_numpy(img_batch)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "landmarks = torch.from_numpy(lm_batch)\n",
    "landmarks.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "img = Variable(img.float()).to(device1)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "landmarks = Variable(landmarks.float()).view(-1,3).to(device1)\n",
    "landmarks.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "output = alexnet(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_batch, test_target = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: torch.nn.Module, \n",
    "                train_dataset: torch.utils.data.Dataset,\n",
    "                val_dataset: torch.utils.data.Dataset,\n",
    "                loss_function: torch.nn.Module = torch.nn.MSELoss(), # loss_function: torch.nn.Module = torch.nn.CrossEntropyLoss() \n",
    "                optimizer_class: Type[torch.optim.Optimizer] = torch.optim,\n",
    "                optimizer_params: Dict = {},\n",
    "                lr_scheduler_class: Any = torch.optim.lr_scheduler.CosineAnnealingLR,\n",
    "                initial_lr = float,\n",
    "                lr_scheduler_params: Dict = {},\n",
    "                max_epochs = 100,\n",
    "                early_stopping_patience = 20):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=initial_lr, **optimizer_params)\n",
    "    lr_scheduler = lr_scheduler_class(optimizer, **lr_scheduler_params)\n",
    "\n",
    "    best_val_loss = None\n",
    "    best_epoch = None\n",
    "    loss_value = []\n",
    "    loss_valueXY = []\n",
    "    loss_valueR = []\n",
    "    \n",
    "    batches_queue_length =16\n",
    "\n",
    "    train_batches_queue = Queue(maxsize=batches_queue_length)\n",
    "    train_cuda_batches_queue = Queue(maxsize=8)\n",
    "    train_thread_killer = thread_killer()\n",
    "    train_thread_killer.set_tokill(False)\n",
    "    preprocess_workers = 16\n",
    "\n",
    "    for _ in range(preprocess_workers):\n",
    "        thr = Thread(target=threaded_batches_feeder, args=(train_thread_killer, train_batches_queue, train_dataset))\n",
    "        thr.start()\n",
    "\n",
    "    train_cuda_transfers_thread_killer = thread_killer()\n",
    "    train_cuda_transfers_thread_killer.set_tokill(False)\n",
    "    train_cudathread = Thread(target=threaded_cuda_batches, args=(train_cuda_transfers_thread_killer, train_cuda_batches_queue,\n",
    "                                                                  train_batches_queue))\n",
    "    train_cudathread.start()\n",
    "    \n",
    "\n",
    "    test_batches_queue = Queue(maxsize=batches_queue_length)\n",
    "    test_cuda_batches_queue = Queue(maxsize=8)\n",
    "    test_thread_killer = thread_killer()\n",
    "    test_thread_killer.set_tokill(False)\n",
    "    preprocess_workers = 16\n",
    "\n",
    "    for _ in range(preprocess_workers):\n",
    "        thr = Thread(target=threaded_batches_feeder, args=(train_thread_killer, test_batches_queue, sun_dataset_test))\n",
    "        thr.start()\n",
    "\n",
    "    test_cuda_transfers_thread_killer = thread_killer()\n",
    "    test_cuda_transfers_thread_killer.set_tokill(False)\n",
    "    test_cudathread = Thread(target=threaded_cuda_batches, args=(test_cuda_transfers_thread_killer, test_cuda_batches_queue,\n",
    "                                                                  test_batches_queue))\n",
    "    test_cudathread.start()\n",
    "    \n",
    "    \n",
    "    Steps_Per_Epoch_Train = len(train_dataset)/batch_size # количество итераций обучения и валидации\n",
    "    Steps_Per_Epoch_Test = len(val_dataset)/batch_size\n",
    "    \n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        \n",
    "        print(f'Epoch {epoch}')\n",
    "        train_single_epoch(model, optimizer, loss_function, train_cuda_batches_queue,Steps_Per_Epoch_Train) # передать х\n",
    "        ######## DEBUG ###########\n",
    "        break\n",
    "        ######## DEBUG ###########\n",
    "        \n",
    "        val_metrics, lossXY, lossR = validate_single_epoch(model, loss_function, test_cuda_batches_queue,Steps_Per_Epoch_Test)\n",
    "        loss_value = np.append(loss_value,val_metrics) # добавляю в массив значение функци потерь\n",
    "        loss_valueXY = np.append(loss_valueXY,lossXY)\n",
    "        loss_valueR = np.append(loss_valueR,lossR)\n",
    "        np.save('loss_value_alexnet3',loss_value )\n",
    "        np.save('loss_valueXY_alexnet3',loss_valueXY )\n",
    "        np.save('loss_valueR_alexnet3',loss_valueR )\n",
    "        print(f'Validation metrics: \\n{val_metrics}')\n",
    "        \n",
    "\n",
    "\n",
    "        lr_scheduler.step() #lr_scheduler.step(val_metrics['loss'])\n",
    "\n",
    "\n",
    "        \n",
    "        if best_val_loss is None or best_val_loss > val_metrics:\n",
    "            print(f'Best model yet, saving')\n",
    "            best_val_loss = val_metrics\n",
    "            best_epoch = epoch\n",
    "            torch.save(model, 'saved_models/best_model_alexnet3.pth') \n",
    "\n",
    "        \n",
    "#         if epoch - best_epoch > early_stopping_patience:\n",
    "#             print('Early stopping triggered')\n",
    "#             return\n",
    "        \n",
    "        \n",
    "    val_thread_killer.set_tokill(True) # убиваю потокои, так же убить валидационные\n",
    "    val_cuda_transfers_thread_killer.set_tokill(True)\n",
    "    for _ in range(preprocess_workers):\n",
    "        try:\n",
    "            # Enforcing thread shutdown\n",
    "            val_batches_queue.get(block=True, timeout=1)\n",
    "            val_cuda_batches_queue.get(block=True, timeout=1)\n",
    "        except Empty:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_single_epoch(model: torch.nn.Module,\n",
    "                        loss_function: torch.nn.Module, \n",
    "                        cuda_batches_queue: Queue, \n",
    "                        Per_Step_Epoch:int):\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    lossXY = 0\n",
    "    lossR = 0\n",
    "    loss1 = 0\n",
    "    loss2 = 0\n",
    "    model.eval()\n",
    "    pbar = tqdm(total=Per_Step_Epoch)\n",
    "    for batch_idx in range(int(Per_Step_Epoch)): # тут продумать \n",
    "        data_image, target = cuda_batches_queue.get(block=True)\n",
    "        data_out = model(data_image)\n",
    "        loss = loss_function(data_out, target) # посчитали на изображении\n",
    "        test_loss += loss.item() # прибавили\n",
    "        loss1 , loss2 = calculate_loss(data_out, target) # тут считаю свои метрики\n",
    "        lossXY +=loss1\n",
    "        lossR  +=loss2\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "    test_loss /= Per_Step_Epoch*batch_size\n",
    "    lossXY    /= Per_Step_Epoch*batch_size # корень извлечь и поправить функцию расчета\n",
    "    lossR     /= Per_Step_Epoch*batch_size  # корень извлечь\n",
    "\n",
    "    return {test_loss,lossXY,lossR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_epoch(model: torch.nn.Module,\n",
    "                    optimizer: torch.optim.Optimizer, \n",
    "                    loss_function: torch.nn.Module,\n",
    "                    cuda_batches_queue: Queue, \n",
    "                    Per_Step_Epoch:int):\n",
    "                    #data_loader: torch.utils.data.DataLoader):\n",
    "\n",
    "    model.train()\n",
    "    pbar = tqdm(total=Per_Step_Epoch)\n",
    "    for batch_idx in range(int(Per_Step_Epoch)): # тут продумать \n",
    "        data_image, target = cuda_batches_queue.get(block=True)\n",
    "#         test_batch.append(data_image.detach().cpu().numpy())\n",
    "#         test_target.append(target.detach().cpu().numpy())\n",
    "        \n",
    "        ######## DEBUG ###########\n",
    "#         print(data_image.shape)\n",
    "#         return {'loss': 0.0}\n",
    "        ######## DEBUG ###########\n",
    "        \n",
    "#         target = Variable(target).view(-1,3) # трансформировали переменные для pytorch , volatile=True\n",
    "        ###### Coords only - without radius ######\n",
    "        target = Variable(target).view(-1,2)\n",
    "        ###### Coords only - without radius ######\n",
    "        \n",
    "#         print(target)\n",
    "        target = target.to(device1)\n",
    "        optimizer.zero_grad() # обнулили\\перезапустии градиенты для обратного распространения\n",
    "        data_out = model(data_image)# применили модель к данным\n",
    "        loss = loss_function(data_out, target) # применили фуннкцию потерь\n",
    "        loss.backward() # пошли по графу нейросетки обратно\n",
    "        optimizer.step()# выполняем наш градиентный спуск по вычисленным шагам в предыдущей строчке\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        \n",
    "        \n",
    "    return {'loss': loss.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/267.625 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 267/267.625 [04:38<00:00,  1.11it/s, loss=0.312]"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'val_thread_killer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-52e02364120f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mlr_scheduler_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCosineAnnealingLR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mlr_scheduler_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'T_max'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'last_epoch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eta_min'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1e-7\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         initial_lr=1e-5)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-a87cb709e5d7>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataset, val_dataset, loss_function, optimizer_class, optimizer_params, lr_scheduler_class, initial_lr, lr_scheduler_params, max_epochs, early_stopping_patience)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mval_thread_killer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tokill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# убиваю потокои, так же убить валидационные\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mval_cuda_transfers_thread_killer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tokill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_thread_killer' is not defined"
     ]
    }
   ],
   "source": [
    "    train_model(alexnet, \n",
    "            train_dataset = sun_dataset_train, \n",
    "            val_dataset =  sun_dataset_test,  \n",
    "            loss_function = torch.nn.MSELoss(), \n",
    "            lr_scheduler_class = torch.optim.lr_scheduler.CosineAnnealingLR,\n",
    "            lr_scheduler_params = {'T_max': 100, 'last_epoch': -1, 'eta_min': 1e-7},\n",
    "            initial_lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_image = test_batch[0]\n",
    "data_image.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "target = test_target[0]\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_image.min(), data_image.max()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "idx = 1\n",
    "plt.imshow(np.transpose(data_image[idx], (1,2,0)).astype(np.uint8), origin='lower')\n",
    "plt.scatter([target[idx][0]*1920], [[target[idx][1]*1920]], s=10, color='magenta')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_out = alexnet(torch.from_numpy(data_image).to(device1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_out.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "l = torch.nn.MSELoss(reduction='none')(model_out, torch.from_numpy(target).to(device1))\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
