{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import cv2 as cv2\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List, Type, Dict, Any\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, datasets\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os.path\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables import Keypoint, KeypointsOnImage\n",
    "import os\n",
    "from threading import Thread\n",
    "from queue import Empty, Queue\n",
    "import threading\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "import accimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(378) # обнулили генератор рандома у торча\n",
    "np.random.seed(378)# обнулили генератор рандома у нампая\n",
    "torch.backends.cudnn.deterministic = True # ждем одинаковый результат у GPU и CPU Для одинаковых данны переданных торчу\n",
    "torch.backends.cudnn.benchmark = False # вроде аналогично строчке выше\n",
    "ia.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.device_count()\n",
    "device1 = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" )\n",
    "print(device1)\n",
    "device2 = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_train(model): # запускаем обучение всех слоев\n",
    "    for param in model.parameters(): \n",
    "        param.requires_grad = True\n",
    "def draw_circle(image, landmarks): # дорисовываем окружность на изображении и возвращаем обратно\n",
    "    imageWithCircle = cv2.circle(image, (int(landmarks[0][0]),int(landmarks[0][1]) ),int(landmarks[0][2]), (255, 0 , 0),  10)\n",
    "    return imageWithCircle\n",
    "\n",
    "\n",
    "def show_landmarks(image, landmarks): # конкретно эта функция, скорее всего не понадобится\n",
    "    \"\"\"Show image with landmarks\"\"\"\n",
    "    plt.imshow(draw_circle(image,landmarks) )\n",
    "    plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker='.', c='r') # начало координат не совпадает , надо учесть\n",
    "    # для картинки надо, для нейросетки не нужно, начало координат должно совпасть\n",
    "    # в numpy 0-левая координата - у, первая - иксы(столбцы)\n",
    "    # порисовать диск солнце порисовать кружочки через opencv(там с координатами тоже не все гладко, надо внимательно смотреть)\n",
    "    # размеры реальных снимков 1920х1920 а не 1200х1200, надо как-то или к долям 1 или сразу в 1920х1920 формат\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    \n",
    "def calculate_loss(model_result : torch.tensor, \n",
    "                   data_target  : torch.tensor,\n",
    "                   loss_function: torch.nn.Module = torch.nn.MSELoss()): #reduction = None\n",
    "    lossXY =  (loss_function(model_result[:,:2], data_target[:,:2]))**(0.5) # тут из батчей получаю, править\n",
    "    lossR =  loss_function(model_result[:,2], data_target[:,2]) # потом корень извлечь\n",
    "    #return {'lossXY': lossXY.item(),'lossR': lossR.item() }\n",
    "    return { lossXY.item(), lossR.item() }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "alexnet = models.alexnet(pretrained=True, progress=False)\n",
    "for p in alexnet.parameters():\n",
    "    print(p.device)\n",
    "    break\n",
    "for param in alexnet.parameters(): # запрещаем обучаться alexnet\n",
    "    param.requires_grad = False\n",
    "alexnet.fc = torch.nn.Sequential(nn.Linear(in_features=2048, out_features=256, bias=True),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(in_features=256, out_features=128, bias=True),\n",
    "                            nn.ReLU(), # SeLU или GeLU возможно подойдут лучше, надо поиграться\n",
    "                            nn.Linear(in_features=128, out_features=3, bias=True)) # мой франкенштейн для регрессии, который подцепили к resnet сфот\n",
    "_ = alexnet.to(device1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "resnet152 = models.resnet152(pretrained=True, progress=False)\n",
    "for p in resnet152.parameters():\n",
    "    print(p.device)\n",
    "    break\n",
    "for param in resnet152.parameters(): # запрещаем обучаться resnet 152\n",
    "    param.requires_grad = False\n",
    "resnet152.fc = torch.nn.Sequential(nn.Linear(in_features=2048, out_features=256, bias=True),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(in_features=256, out_features=128, bias=True),\n",
    "                            nn.ReLU(), # SeLU или GeLU возможно подойдут лучше, надо поиграться\n",
    "                            nn.Linear(in_features=128, out_features=3, bias=True)) # мой франкенштейн для регрессии, который подцепили к resnet сфот\n",
    "_ = resnet152.to(device1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# упомянуть челиков из imgaug\n",
    "## тут агментация данных дальше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),# horizontally flip 20% of the images flipud\n",
    "    iaa.Flipud(0.5),# vertically flip 20% of the images flipud добавить на 180 градусов поворот\n",
    "    iaa.GaussianBlur(sigma=(0, 5)), # blur images with a sigma of 0 to 0.5\n",
    "    #iaa.Invert(0.1) # пока уберем\n",
    "    iaa.Affine(rotate=(-180,180))# поворот на 180 через афииные преобразования\n",
    "])\n",
    "# kps = KeypointsOnImage([\n",
    "#     Keypoint(x=landmarks[:,0], y=landmarks[:,1])\n",
    "# ], shape=(1920,1920,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(dataset_dir):\n",
    "    image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir)]\n",
    "    return image_filenames\n",
    "\n",
    "\n",
    "class thread_killer(object):    \n",
    "    \"\"\"Boolean object for signaling a worker thread to terminate\"\"\"\n",
    "    def __init__(self):\n",
    "        self.to_kill = False\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.to_kill\n",
    "\n",
    "    def set_tokill(self, tokill):\n",
    "        self.to_kill = tokill\n",
    "\n",
    "\n",
    "def threaded_batches_feeder(tokill, batches_queue, dataset_generator):\n",
    "    while tokill() == False:\n",
    "        for img, landmarks in dataset_generator:\n",
    "            batches_queue.put((img, landmarks), block=True)\n",
    "            if tokill() == True:\n",
    "                return\n",
    "\n",
    "\n",
    "def threaded_cuda_batches(tokill,cuda_batches_queue,batches_queue):\n",
    "    while tokill() == False:\n",
    "        (img, landmarks) = batches_queue.get(block=True)\n",
    "        img = torch.from_numpy(img)\n",
    "        landmarks = torch.from_numpy(landmarks)       \n",
    "        \n",
    "        img = Variable(img.float()).to(device1)\n",
    "        landmarks = Variable(landmarks.float()).view(-1,3).to(device1)\n",
    "        \n",
    "        cuda_batches_queue.put((img, landmarks), block=True)\n",
    "        \n",
    "        if tokill() == True:\n",
    "            return\n",
    "\n",
    "\n",
    "class threadsafe_iter:\n",
    "    \"\"\"\n",
    "    Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            return next(self.it)\n",
    "\n",
    "def get_objects_i(objects_count):\n",
    "    \"\"\"Cyclic generator of paths indices\n",
    "    \"\"\"\n",
    "    current_objects_id = 0\n",
    "    while True:\n",
    "        yield current_objects_id\n",
    "        current_objects_id  = (current_objects_id + 1) % objects_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for item, url in enumerate(urls):\n",
    "#     name = \"Поток %s\" % (item+1)\n",
    "#     thread = DownloadThread(url, name)\n",
    "#     thread.start()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SunLandmarksDataset(Dataset):\n",
    "    \"\"\"Sun Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform = None, batch_size = 10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(csv_file,delimiter=',')\n",
    "        self.root_dir = root_dir\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.objects_id_generator = threadsafe_iter(get_objects_i(self.landmarks_frame.shape[0]))\n",
    "        \n",
    "        self.lock = threading.Lock()  # mutex for input path\n",
    "        self.yield_lock = threading.Lock()  # mutex for generator yielding of batch\n",
    "        self.init_count = 0\n",
    "        self.cache = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def shuffle(self):\n",
    "        self.landmarks_frame = shuffle(self.landmarks_frame)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            with self.lock:\n",
    "                if (self.init_count == 0):\n",
    "                    self.shuffle()\n",
    "                    self.imgs = []\n",
    "                    self.landmarks = []\n",
    "                    self.init_count = 1\n",
    "            \n",
    "            for obj_id in self.objects_id_generator:\n",
    "                img_name = os.path.join(self.root_dir , self.landmarks_frame.iloc[obj_id, 0])\n",
    "                if img_name in self.cache:\n",
    "                    img = self.cache[img_name]\n",
    "                else:\n",
    "                    img = accimage.Image(img_name)\n",
    "                    image_np = np.empty([img.channels, img.height, img.width], dtype=np.uint8)\n",
    "                    img.copyto(image_np)\n",
    "                    self.cache[img_name] = img\n",
    "                    \n",
    "                img = np.transpose(image_np, (1, 2, 0))\n",
    "                \n",
    "                landmarks = self.landmarks_frame.iloc[obj_id, 1:]\n",
    "                landmarks = np.array([landmarks])\n",
    "                landmarks = landmarks.astype('float').reshape(1, 3)\n",
    "                \n",
    "                kps = KeypointsOnImage([\n",
    "                        Keypoint(x=landmarks[0,0]*1920, y=landmarks[0,1]*1920) # домножил, тк нормировал\n",
    "                ], shape=img.shape)\n",
    "                image_aug, landmarks_after =seq(image = img, keypoints = kps) # тут применяю аугментацию к фотке и целевой переменной\n",
    "                landmarks[0,0] = landmarks_after.keypoints[0].x/1920 # обратно отнормировал \n",
    "                landmarks[0,1] = landmarks_after.keypoints[0].y/1920\n",
    "                img = image_aug\n",
    "                \n",
    "                img = img.transpose((2, 0, 1))[np.newaxis,...] # для тензоров\n",
    "#                 landmarks = self.landmarks_frame.iloc[obj_id, 1:]\n",
    "#                 landmarks = np.array([landmarks])\n",
    "                landmarks = landmarks[np.newaxis,...]\n",
    "                \n",
    "                # Concurrent access by multiple threads to the lists below\n",
    "                with self.yield_lock:\n",
    "                    if (len(self.imgs)) < self.batch_size:\n",
    "                        self.imgs.append(img)\n",
    "                        self.landmarks.append(landmarks)\n",
    "                    if len(self.imgs) % self.batch_size == 0:\n",
    "                        self.imgs = np.concatenate(self.imgs, axis=0)\n",
    "                        self.landmarks = np.concatenate(self.landmarks, axis=0)\n",
    "                        yield (self.imgs, self.landmarks)\n",
    "                        self.imgs, self.landmarks = [], []\n",
    "                        \n",
    "            # At the end of an epoch we re-init data-structures\n",
    "            with self.lock:\n",
    "                self.landmarks_frame = shuffle(self.landmarks_frame)\n",
    "                self.init_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = image.copy() # какая-та жопа была с шагом, текст ошибки прямо советовал просто копировать\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'landmarks': torch.from_numpy(landmarks)}\n",
    "\n",
    "# class ToTensor(object):\n",
    "#     \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "#     def __call__(self, sample):\n",
    "#         image = sample\n",
    "#         return torch.from_numpy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "sun_dataset_train = SunLandmarksDataset(csv_file='sun_disk_pos_database01train.csv',\n",
    "                                           root_dir='/app/images',\n",
    "                                           transform=transforms.Compose([\n",
    "                                               ToTensor()\n",
    "                                           ]), batch_size=batch_size)\n",
    "sun_dataset_test = SunLandmarksDataset(csv_file='sun_disk_pos_database01test.csv',\n",
    "                                           root_dir='/app/images',\n",
    "                                           transform=transforms.Compose([\n",
    "                                               ToTensor()\n",
    "                                           ]), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: torch.nn.Module, \n",
    "                train_dataset: torch.utils.data.Dataset,\n",
    "                val_dataset: torch.utils.data.Dataset,\n",
    "                loss_function: torch.nn.Module = torch.nn.MSELoss(), # loss_function: torch.nn.Module = torch.nn.CrossEntropyLoss() \n",
    "                optimizer_class: Type[torch.optim.Optimizer] = torch.optim,\n",
    "                optimizer_params: Dict = {},\n",
    "                lr_scheduler_class: Any = torch.optim.lr_scheduler.CosineAnnealingLR,\n",
    "                initial_lr = float,\n",
    "                lr_scheduler_params: Dict = {},\n",
    "                batch_size = int,\n",
    "                max_epochs = 100,\n",
    "                early_stopping_patience = 20):\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=initial_lr, **optimizer_params)\n",
    "    lr_scheduler = lr_scheduler_class(optimizer, **lr_scheduler_params)\n",
    "\n",
    "#     train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size,drop_last=False)\n",
    "#     val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,drop_last=False)\n",
    "    \n",
    "    best_val_loss = None\n",
    "    best_epoch = None\n",
    "    loss_value = []\n",
    "    loss_valueXY = []\n",
    "    loss_valueR = []\n",
    "    \n",
    "    batches_queue_length =16\n",
    "\n",
    "    train_batches_queue = Queue(maxsize=batches_queue_length)\n",
    "    train_cuda_batches_queue = Queue(maxsize=8)\n",
    "    train_thread_killer = thread_killer()\n",
    "    train_thread_killer.set_tokill(False)\n",
    "    preprocess_workers = 16\n",
    "\n",
    "    for _ in range(preprocess_workers):\n",
    "        thr = Thread(target=threaded_batches_feeder, args=(train_thread_killer, train_batches_queue, train_dataset))\n",
    "        thr.start()\n",
    "\n",
    "    train_cuda_transfers_thread_killer = thread_killer()\n",
    "    train_cuda_transfers_thread_killer.set_tokill(False)\n",
    "    train_cudathread = Thread(target=threaded_cuda_batches, args=(train_cuda_transfers_thread_killer, train_cuda_batches_queue,\n",
    "                                                                  train_batches_queue))\n",
    "    train_cudathread.start()\n",
    "    \n",
    "\n",
    "    test_batches_queue = Queue(maxsize=batches_queue_length)\n",
    "    test_cuda_batches_queue = Queue(maxsize=8)\n",
    "    test_thread_killer = thread_killer()\n",
    "    test_thread_killer.set_tokill(False)\n",
    "    preprocess_workers = 16\n",
    "\n",
    "    for _ in range(preprocess_workers):\n",
    "        thr = Thread(target=threaded_batches_feeder, args=(train_thread_killer, test_batches_queue, sun_dataset_test))\n",
    "        thr.start()\n",
    "\n",
    "    test_cuda_transfers_thread_killer = thread_killer()\n",
    "    test_cuda_transfers_thread_killer.set_tokill(False)\n",
    "    test_cudathread = Thread(target=threaded_cuda_batches, args=(test_cuda_transfers_thread_killer, test_cuda_batches_queue,\n",
    "                                                                  test_batches_queue))\n",
    "    test_cudathread.start()\n",
    "    \n",
    "    \n",
    "    Steps_Per_Epoch_Train = len(train_dataset)/batch_size # количество итераций обучения и валидации\n",
    "    Steps_Per_Epoch_Test = len(val_dataset)/batch_size\n",
    "    \n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        \n",
    "        print(f'Epoch {epoch}')\n",
    "        train_single_epoch(model, optimizer, loss_function, train_cuda_batches_queue,Steps_Per_Epoch_Train) # передать х\n",
    "        val_metrics, lossXY, lossR = validate_single_epoch(model, loss_function, test_cuda_batches_queue,Steps_Per_Epoch_Test)\n",
    "        loss_value = np.append(loss_value,val_metrics) # добавляю в массив значение функци потерь\n",
    "        loss_valueXY = np.append(loss_valueXY,lossXY)\n",
    "        loss_valueR = np.append(loss_valueR,lossR)\n",
    "        np.save('loss_value+aug+proc',loss_value )\n",
    "        np.save('loss_valueXY+aug+proc',loss_valueXY )\n",
    "        np.save('loss_valueR+aug+proc',loss_valueR )\n",
    "        print(f'Validation metrics: \\n{val_metrics}')\n",
    "        \n",
    "\n",
    "\n",
    "        lr_scheduler.step() #lr_scheduler.step(val_metrics['loss'])\n",
    "\n",
    "\n",
    "        \n",
    "        if best_val_loss is None or best_val_loss > val_metrics:\n",
    "            print(f'Best model yet, saving')\n",
    "            best_val_loss = val_metrics\n",
    "            best_epoch = epoch\n",
    "            torch.save(model, 'saved_models/best_model+aug+proc.pth') \n",
    "\n",
    "        \n",
    "        if epoch - best_epoch > early_stopping_patience:\n",
    "            print('Early stopping triggered')\n",
    "            return\n",
    "        \n",
    "        \n",
    "    val_thread_killer.set_tokill(True) # убиваю потокои, так же убить валидационные\n",
    "    val_cuda_transfers_thread_killer.set_tokill(True)\n",
    "    for _ in range(preprocess_workers):\n",
    "        try:\n",
    "            # Enforcing thread shutdown\n",
    "            val_batches_queue.get(block=True, timeout=1)\n",
    "            val_cuda_batches_queue.get(block=True, timeout=1)\n",
    "        except Empty:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_single_epoch(model: torch.nn.Module,\n",
    "                        loss_function: torch.nn.Module, \n",
    "                        cuda_batches_queue: Queue, \n",
    "                        Per_Step_Epoch:int):\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    lossXY = 0\n",
    "    lossR = 0\n",
    "    loss1 = 0\n",
    "    loss2 = 0\n",
    "    model.eval()\n",
    "    for batch_idx in range(int(Per_Step_Epoch)): # тут продумать \n",
    "        data_image, target = cuda_batches_queue.get(block=True)\n",
    "        data_out = model(data_image)\n",
    "        loss = loss_function(data_out, target) # посчитали на изображении\n",
    "        test_loss += loss.item() # прибавили\n",
    "        loss1 , loss2 = calculate_loss(data_out, target) # тут считаю свои метрики\n",
    "        lossXY +=loss1\n",
    "        lossR  +=loss2\n",
    "        \n",
    "    test_loss /= Per_Step_Epoch*batch_size\n",
    "    lossXY    /= Per_Step_Epoch*batch_size # корень извлечь и поправить функцию расчета\n",
    "    lossR     /= Per_Step_Epoch*batch_size  # корень извлечь\n",
    "    # print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    #      test_loss, correct, len(data_loader.dataset),\n",
    "    #      100. * correct / len(data_loader.dataset)))\n",
    "    #return {'loss':test_loss,'lossXY':lossXY,'lossR':lossR, } #, correct\n",
    "    #return {'loss':test_loss,'lossXY':lossXY,'lossR':lossR}\n",
    "    return {test_loss,lossXY,lossR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_epoch(model: torch.nn.Module,\n",
    "                    optimizer: torch.optim.Optimizer, \n",
    "                    loss_function: torch.nn.Module,\n",
    "                    cuda_batches_queue: Queue, \n",
    "                    Per_Step_Epoch:int):\n",
    "                    #data_loader: torch.utils.data.DataLoader):\n",
    "\n",
    "    model.train()\n",
    "    pbar = tqdm(total=Per_Step_Epoch)\n",
    "    for batch_idx in range(int(Per_Step_Epoch)): # тут продумать \n",
    "        data_image, target = cuda_batches_queue.get(block=True)\n",
    "        print(data_image.size())\n",
    "        target = Variable(target).view(-1,3) # трансформировали переменные для pytorch , volatile=True\n",
    "        target = target.to(device1)\n",
    "        optimizer.zero_grad() # обнулили\\перезапустии градиенты для обратного распространения\n",
    "        data_out = model(data_image) # применили модель к данным\n",
    "        loss = loss_function(data_out, target) # применили фуннкцию потерь\n",
    "        loss.backward() # пошли по графу нейросетки обратно\n",
    "        optimizer.step()# выполняем наш градиентный спуск по вычисленным шагам в предыдущей строчке\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        \n",
    "        \n",
    "    return {'loss': loss.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/214.1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "<built-in method size of Tensor object at 0x7f7930164d38>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/214.1 [00:26<1:35:20, 26.84s/it, loss=0.179]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method size of Tensor object at 0x7f793016c630>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unable to find a valid cuDNN algorithm to run convolution",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-68632fad4004>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mlr_scheduler_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'T_max'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'last_epoch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eta_min'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1e-7\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0minitial_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         batch_size = 10)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-3f8cc206f92e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataset, val_dataset, loss_function, optimizer_class, optimizer_params, lr_scheduler_class, initial_lr, lr_scheduler_params, batch_size, max_epochs, early_stopping_patience)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mtrain_single_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_cuda_batches_queue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSteps_Per_Epoch_Train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# передать х\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mval_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossXY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_single_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_cuda_batches_queue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSteps_Per_Epoch_Test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_metrics\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# добавляю в массив значение функци потерь\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-407d3eb3c6ff>\u001b[0m in \u001b[0;36mtrain_single_epoch\u001b[0;34m(model, optimizer, loss_function, cuda_batches_queue, Per_Step_Epoch)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# обнулили\\перезапустии градиенты для обратного распространения\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mdata_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_image\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# применили модель к данным\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# применили фуннкцию потерь\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# пошли по графу нейросетки обратно\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    372\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    373\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 374\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unable to find a valid cuDNN algorithm to run convolution"
     ]
    }
   ],
   "source": [
    "    train_model(resnet152, \n",
    "            train_dataset = sun_dataset_train, \n",
    "            val_dataset =  sun_dataset_test,  \n",
    "            loss_function = torch.nn.MSELoss(), \n",
    "            lr_scheduler_class = torch.optim.lr_scheduler.CosineAnnealingLR,\n",
    "            lr_scheduler_params = {'T_max': 100, 'last_epoch': -1, 'eta_min': 1e-7},\n",
    "            initial_lr=1e-4,\n",
    "            batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
